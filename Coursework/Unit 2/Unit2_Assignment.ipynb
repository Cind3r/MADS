{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c62c615-7555-4d80-8cd0-b1dc40432d8e",
   "metadata": {},
   "source": [
    "# Graded: x of 8 correct\n",
    "- [x] Read the text file\n",
    "- [x] Remove punctuation\n",
    "- [x] Convert to lowercase\n",
    "- [x] Split into words\n",
    "- [x] Create a `set` of unique words\n",
    "- [x] Dictionary of word counts\n",
    "- [x] Display unique words and frequencies\n",
    "- [x] Code organization and comments\n",
    "\n",
    "Comments: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b9b181-ebe4-49aa-ae71-0bd72176b056",
   "metadata": {},
   "source": [
    "## Unit 2 Programming Assignment\n",
    "* The objective of this assignment is for you to write code that reads a text file and computes on the text data.\n",
    "* Your program should read a text file, do some cleaning of the text and compute word statistics.\n",
    "* In particular, the code should:\n",
    "    1. Read the content of the text file `Unit2_Python_learning_journey.txt`.\n",
    "        * The text in this file is from the free Python text book, [Python for everybody](https://www.py4e.com/book.php)\n",
    "    2. Remove punctuation and convert all words to lowercase.\n",
    "    3. Split the text into individual words.\n",
    "    4. Use a set to find all unique words.\n",
    "    5. Use a dictionary to count the frequency of each unique word.\n",
    "    6. Display each unique word along with its frequency.\n",
    "* You should organize your code appropriately to show a clean and thoughtful design.\n",
    "    * Use functions as needed.\n",
    "    * Break up into cells so smaller pieces can be easily tested.\n",
    "    * Add the appropriate documentation to make your code comprehensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc97b5b",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "79491e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate # This is just for the table, not needed for the exercise\n",
    "# -*- coding: utf-8 -*- for apostrophes \n",
    "\n",
    "# Load the text file into a string\n",
    "text_file = open(\"Unit2_Python_learning_journey.txt\", \"r\", encoding='utf-8')\n",
    "text = \"\".join(text_file.readlines())\n",
    "text_file.close()\n",
    "\n",
    "# Create data scructures to store the words\n",
    "myDict = {}\n",
    "mySet = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b28ded",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "79112d3d-c6af-405b-b8f4-cc54aeedfa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Alter the text to remove punctuation and make it lowercase\n",
    "def remove_punctuation(text):\n",
    "    punctuation = '''!()-[]{};:\"\\,<>./?’@#$%^&*_~\\n''' # had to grab a ’ (curly apostrophe) from the internet so it would remove it as well\n",
    "    for char in text:\n",
    "        if char in punctuation:\n",
    "            text = text.replace(char, \"\")\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "# Split the text into words\n",
    "def split_text(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "# Get all the unique words\n",
    "def get_unique_words(words):\n",
    "    for word in words:\n",
    "        mySet.add(word)\n",
    "    \n",
    "    # add to dictioary for frequency count\n",
    "    myDict = dict.fromkeys(mySet, 0)\n",
    "\n",
    "\n",
    "# Count the frequency of each word\n",
    "def count_words(words):\n",
    "    for word in words:\n",
    "        if word in myDict:\n",
    "            myDict[word] += 1\n",
    "        else:\n",
    "            myDict[word] = 1\n",
    "\n",
    "\n",
    "# clean the set and dictionary\n",
    "def clean_data():\n",
    "    mySet.clear()\n",
    "    myDict.clear()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399cb40",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "922c7404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of each word in the text is...\n",
      "\n",
      "Word \t\t|\t\t Frequency\n",
      "| Word          |   Frequency |\n",
      "|---------------+-------------|\n",
      "| you           |          20 |\n",
      "| to            |          18 |\n",
      "| a             |          17 |\n",
      "| and           |          17 |\n",
      "| the           |          15 |\n",
      "| it            |          12 |\n",
      "| that          |           9 |\n",
      "| are           |           7 |\n",
      "| of            |           5 |\n",
      "| if            |           5 |\n",
      "| material      |           5 |\n",
      "| time          |           4 |\n",
      "| your          |           4 |\n",
      "| few           |           4 |\n",
      "| more          |           4 |\n",
      "| we            |           4 |\n",
      "| at            |           4 |\n",
      "| in            |           4 |\n",
      "| with          |           4 |\n",
      "| book          |           3 |\n",
      "| dont          |           3 |\n",
      "| be            |           3 |\n",
      "| first         |           3 |\n",
      "| learning      |           3 |\n",
      "| was           |           3 |\n",
      "| years         |           3 |\n",
      "| took          |           3 |\n",
      "| from          |           3 |\n",
      "| all           |           3 |\n",
      "| is            |           3 |\n",
      "| see           |           3 |\n",
      "| up            |           3 |\n",
      "| will          |           3 |\n",
      "| look          |           3 |\n",
      "| programming   |           3 |\n",
      "| as            |           2 |\n",
      "| progress      |           2 |\n",
      "| concepts      |           2 |\n",
      "| when          |           2 |\n",
      "| problem       |           2 |\n",
      "| for           |           2 |\n",
      "| move          |           2 |\n",
      "| simple        |           2 |\n",
      "| sentences     |           2 |\n",
      "| learn         |           2 |\n",
      "| language      |           2 |\n",
      "| absorb        |           2 |\n",
      "| some          |           2 |\n",
      "| get           |           2 |\n",
      "| big           |           2 |\n",
      "| picture       |           2 |\n",
      "| while         |           2 |\n",
      "| by            |           2 |\n",
      "| understanding |           2 |\n",
      "| can           |           2 |\n",
      "| even          |           2 |\n",
      "| staring       |           2 |\n",
      "| seems         |           2 |\n",
      "| bit           |           2 |\n",
      "| usually       |           2 |\n",
      "| there         |           2 |\n",
      "| away          |           2 |\n",
      "| take          |           2 |\n",
      "| back          |           2 |\n",
      "| through       |           1 |\n",
      "| rest          |           1 |\n",
      "| afraid        |           1 |\n",
      "| seem          |           1 |\n",
      "| fit           |           1 |\n",
      "| together      |           1 |\n",
      "| well          |           1 |\n",
      "| were          |           1 |\n",
      "| speak         |           1 |\n",
      "| not           |           1 |\n",
      "| just          |           1 |\n",
      "| made          |           1 |\n",
      "| cute          |           1 |\n",
      "| gurgling      |           1 |\n",
      "| noises        |           1 |\n",
      "| ok            |           1 |\n",
      "| six           |           1 |\n",
      "| months        |           1 |\n",
      "| vocabulary    |           1 |\n",
      "| 56            |           1 |\n",
      "| paragraphs    |           1 |\n",
      "| able          |           1 |\n",
      "| write         |           1 |\n",
      "| an            |           1 |\n",
      "| interesting   |           1 |\n",
      "| complete      |           1 |\n",
      "| short         |           1 |\n",
      "| story         |           1 |\n",
      "| on            |           1 |\n",
      "| own           |           1 |\n",
      "| want          |           1 |\n",
      "| python        |           1 |\n",
      "| much          |           1 |\n",
      "| rapidly       |           1 |\n",
      "| so            |           1 |\n",
      "| teach         |           1 |\n",
      "| same          |           1 |\n",
      "| over          |           1 |\n",
      "| next          |           1 |\n",
      "| chapters      |           1 |\n",
      "| but           |           1 |\n",
      "| like          |           1 |\n",
      "| new           |           1 |\n",
      "| takes         |           1 |\n",
      "| understand    |           1 |\n",
      "| before        |           1 |\n",
      "| feels         |           1 |\n",
      "| natural       |           1 |\n",
      "| leads         |           1 |\n",
      "| confusion     |           1 |\n",
      "| visit         |           1 |\n",
      "| revisit       |           1 |\n",
      "| topics        |           1 |\n",
      "| try           |           1 |\n",
      "| defining      |           1 |\n",
      "| tiny          |           1 |\n",
      "| fragments     |           1 |\n",
      "| make          |           1 |\n",
      "| written       |           1 |\n",
      "| linearly      |           1 |\n",
      "| taking        |           1 |\n",
      "| course        |           1 |\n",
      "| linear        |           1 |\n",
      "| fashion       |           1 |\n",
      "| hesitate      |           1 |\n",
      "| very          |           1 |\n",
      "| nonlinear     |           1 |\n",
      "| how           |           1 |\n",
      "| approach      |           1 |\n",
      "| forwards      |           1 |\n",
      "| backwards     |           1 |\n",
      "| read          |           1 |\n",
      "| light         |           1 |\n",
      "| touch         |           1 |\n",
      "| skimming      |           1 |\n",
      "| advanced      |           1 |\n",
      "| without       |           1 |\n",
      "| fully         |           1 |\n",
      "| details       |           1 |\n",
      "| better        |           1 |\n",
      "| why           |           1 |\n",
      "| reviewing     |           1 |\n",
      "| previous      |           1 |\n",
      "| redoing       |           1 |\n",
      "| earlier       |           1 |\n",
      "| exercises     |           1 |\n",
      "| realize       |           1 |\n",
      "| actually      |           1 |\n",
      "| learned       |           1 |\n",
      "| lot           |           1 |\n",
      "| currently     |           1 |\n",
      "| impenetrable  |           1 |\n",
      "| wonderful     |           1 |\n",
      "| ah            |           1 |\n",
      "| hah           |           1 |\n",
      "| moments       |           1 |\n",
      "| where         |           1 |\n",
      "| pounding      |           1 |\n",
      "| rock          |           1 |\n",
      "| hammer        |           1 |\n",
      "| chisel        |           1 |\n",
      "| step          |           1 |\n",
      "| indeed        |           1 |\n",
      "| building      |           1 |\n",
      "| beautiful     |           1 |\n",
      "| sculpture     |           1 |\n",
      "| something     |           1 |\n",
      "| particularly  |           1 |\n",
      "| hard          |           1 |\n",
      "| no            |           1 |\n",
      "| value         |           1 |\n",
      "| staying       |           1 |\n",
      "| night         |           1 |\n",
      "| break         |           1 |\n",
      "| nap           |           1 |\n",
      "| have          |           1 |\n",
      "| snack         |           1 |\n",
      "| explain       |           1 |\n",
      "| what          |           1 |\n",
      "| having        |           1 |\n",
      "| someone       |           1 |\n",
      "| or            |           1 |\n",
      "| perhaps       |           1 |\n",
      "| dog           |           1 |\n",
      "| then          |           1 |\n",
      "| come          |           1 |\n",
      "| fresh         |           1 |\n",
      "| eyes          |           1 |\n",
      "| i             |           1 |\n",
      "| assure        |           1 |\n",
      "| once          |           1 |\n",
      "| really        |           1 |\n",
      "| easy          |           1 |\n",
      "| elegant       |           1 |\n",
      "| simply        |           1 |\n"
     ]
    }
   ],
   "source": [
    "# Empty the set and dictionary to prevent data from previous runs from affecting the current run\n",
    "clean_data()\n",
    "\n",
    "# Take input text and alter it to remove punctuation\n",
    "text = remove_punctuation(text)\n",
    "\n",
    "# Split the text into words\n",
    "words = split_text(text)\n",
    "\n",
    "# Get all the unique words\n",
    "get_unique_words(words)\n",
    "\n",
    "# Count the frequency of each word\n",
    "count_words(words)\n",
    "\n",
    "# Sort for convenience\n",
    "myDict_sorted = dict(sorted(myDict.items(), key=lambda item: item[1], reverse=True))\n",
    "width = 20\n",
    "\n",
    "# Format the output\n",
    "print(\"The frequency of each word in the text is...\\n\")\n",
    "print(f\"Word \\t\\t|\\t\\t Frequency\")\n",
    "\n",
    "# Print the frequency of each word\n",
    "for word in myDict_sorted:\n",
    "    \n",
    "    print(f\"{word:{width}} {myDict_sorted[word]:{width}}\")\n",
    "\n",
    "# This is to print a neater table, but it's not needed for the exercise, uncomment if you want to use it (also need to uncomment import)\n",
    "#table_data = [[key, value] for key, value in myDict_sorted.items()]\n",
    "#print(tabulate(table_data, headers=['Word', 'Frequency'], tablefmt='orgtbl'))\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
